#!/usr/bin/env python3
# example_batch_simulations.py
# Exemplo de como executar m√∫ltiplas simula√ß√µes de forma program√°tica

"""
Este script demonstra como executar m√∫ltiplas simula√ß√µes
personalizadas de forma program√°tica.

Use este como template para criar seus pr√≥prios experimentos em batch.
"""

from advanced_experiments import (
    setup_experiment_directories,
    run_advanced_experiment,
    save_results,
    logger
)
import matplotlib.pyplot as plt
import numpy as np


def example_1_compare_noise_with_dropout():
    """Exemplo 1: Comparar robustez ao ru√≠do com e sem dropout."""

    logger.info("\n" + "="*80)
    logger.info("EXEMPLO 1: RU√çDO COM E SEM DROPOUT")
    logger.info("="*80 + "\n")

    dirs = setup_experiment_directories(base_dir="outputs_example_1")

    # Configura√ß√µes base
    base_config = {
        'initializer': 'he',
        'optimizer': 'adam',
        'learning_rate': 1e-3,
        'hidden_units': 64,
        'batch_size': 128,
        'epochs': 15,
        'activation': 'relu',
        'seed': 42,
        'patience': 3,
        'validation_split': 0.1,
        'save_model': False
    }

    # Experimentos: variar ru√≠do e dropout
    experiments = []

    for noise in [0.1, 0.2, 0.3]:
        for dropout in [0.0, 0.2, 0.4]:
            config = base_config.copy()
            config['noise_std'] = noise
            config['dropout_rate'] = dropout
            config['run_name'] = f'noise_{noise:.1f}_dropout_{dropout:.1f}'
            experiments.append(config)

    # Executar experimentos
    results = []
    for i, config in enumerate(experiments, 1):
        logger.info(f"\nExperimento {i}/{len(experiments)}: {config['run_name']}")
        result = run_advanced_experiment(config, dirs)
        results.append(result)

    # Criar visualiza√ß√£o customizada
    create_noise_dropout_heatmap(results, dirs)

    logger.info(f"\n‚úÖ Exemplo 1 conclu√≠do! Resultados em: {dirs['base']}")
    return results


def example_2_learning_rate_sweep():
    """Exemplo 2: Varredura fina de learning rates."""

    logger.info("\n" + "="*80)
    logger.info("EXEMPLO 2: VARREDURA DE LEARNING RATES")
    logger.info("="*80 + "\n")

    dirs = setup_experiment_directories(base_dir="outputs_example_2")

    # Learning rates em escala logar√≠tmica
    learning_rates = np.logspace(-4, -2, 10)  # 10 valores entre 1e-4 e 1e-2

    results = []

    for lr in learning_rates:
        config = {
            'run_name': f'lr_{lr:.6f}',
            'initializer': 'he',
            'optimizer': 'adam',
            'learning_rate': float(lr),
            'hidden_units': 64,
            'batch_size': 128,
            'epochs': 15,
            'noise_std': 0.2,
            'dropout_rate': 0.0,
            'activation': 'relu',
            'seed': 42,
            'patience': 3,
            'validation_split': 0.1,
            'save_model': False
        }

        logger.info(f"\nTestando LR: {lr:.6f}")
        result = run_advanced_experiment(config, dirs)
        results.append(result)

    # Criar gr√°fico espec√≠fico
    create_lr_sweep_plot(results, dirs)

    logger.info(f"\n‚úÖ Exemplo 2 conclu√≠do! Resultados em: {dirs['base']}")
    return results


def example_3_activation_comparison():
    """Exemplo 3: Compara√ß√£o detalhada de ativa√ß√µes."""

    logger.info("\n" + "="*80)
    logger.info("EXEMPLO 3: COMPARA√á√ÉO DE ATIVA√á√ïES")
    logger.info("="*80 + "\n")

    dirs = setup_experiment_directories(base_dir="outputs_example_3")

    # Cada ativa√ß√£o com seu inicializador ideal
    activations_config = [
        ('relu', 'he'),
        ('elu', 'he'),
        ('tanh', 'glorot'),
        ('sigmoid', 'glorot')
    ]

    results = []

    for activation, initializer in activations_config:
        config = {
            'run_name': f'{activation}_{initializer}',
            'initializer': initializer,
            'optimizer': 'adam',
            'learning_rate': 1e-3,
            'hidden_units': 64,
            'batch_size': 128,
            'epochs': 15,
            'noise_std': 0.2,
            'dropout_rate': 0.0,
            'activation': activation,
            'seed': 42,
            'patience': 3,
            'validation_split': 0.1,
            'save_model': False
        }

        logger.info(f"\nTestando: {activation} com {initializer}")
        result = run_advanced_experiment(config, dirs)
        results.append(result)

    # Criar visualiza√ß√£o comparativa
    create_activation_comparison_plot(results, dirs)

    logger.info(f"\n‚úÖ Exemplo 3 conclu√≠do! Resultados em: {dirs['base']}")
    return results


def example_4_optimal_configuration_search():
    """Exemplo 4: Busca por configura√ß√£o √≥tima."""

    logger.info("\n" + "="*80)
    logger.info("EXEMPLO 4: BUSCA DE CONFIGURA√á√ÉO √ìTIMA")
    logger.info("="*80 + "\n")

    dirs = setup_experiment_directories(base_dir="outputs_example_4")

    # Grid search simplificado
    learning_rates = [5e-4, 1e-3, 2e-3]
    dropouts = [0.0, 0.2, 0.3]
    batch_sizes = [64, 128, 256]

    results = []

    total = len(learning_rates) * len(dropouts) * len(batch_sizes)
    current = 0

    for lr in learning_rates:
        for dropout in dropouts:
            for batch_size in batch_sizes:
                current += 1
                config = {
                    'run_name': f'lr{lr:.0e}_drop{dropout:.1f}_batch{batch_size}',
                    'initializer': 'he',
                    'optimizer': 'adam',
                    'learning_rate': lr,
                    'hidden_units': 64,
                    'batch_size': batch_size,
                    'epochs': 15,
                    'noise_std': 0.2,
                    'dropout_rate': dropout,
                    'activation': 'relu',
                    'seed': 42,
                    'patience': 3,
                    'validation_split': 0.1,
                    'save_model': False
                }

                logger.info(f"\nConfiguracao {current}/{total}: {config['run_name']}")
                result = run_advanced_experiment(config, dirs)
                results.append(result)

    # Encontrar melhor configura√ß√£o
    best_acc = max(results, key=lambda x: x['clean_accuracy'])
    best_robust = min(results, key=lambda x: x['degradation'])

    logger.info("\n" + "="*80)
    logger.info("MELHORES CONFIGURA√á√ïES ENCONTRADAS")
    logger.info("="*80)
    logger.info(f"\nüèÜ Melhor Accuracy: {best_acc['run_name']}")
    logger.info(f"   Accuracy: {best_acc['clean_accuracy']:.4f}")
    logger.info(f"   LR: {best_acc['config']['learning_rate']}")
    logger.info(f"   Dropout: {best_acc['config']['dropout_rate']}")
    logger.info(f"   Batch: {best_acc['config']['batch_size']}")

    logger.info(f"\nüõ°Ô∏è  Mais Robusto: {best_robust['run_name']}")
    logger.info(f"   Degrada√ß√£o: {best_robust['degradation']:.2f}%")
    logger.info(f"   LR: {best_robust['config']['learning_rate']}")
    logger.info(f"   Dropout: {best_robust['config']['dropout_rate']}")
    logger.info(f"   Batch: {best_robust['config']['batch_size']}")

    save_results(results, dirs, "grid_search")

    logger.info(f"\n‚úÖ Exemplo 4 conclu√≠do! Resultados em: {dirs['base']}")
    return results


# ========== FUN√á√ïES DE VISUALIZA√á√ÉO ==========

def create_noise_dropout_heatmap(results, dirs):
    """Cria heatmap de degrada√ß√£o vs. noise e dropout."""

    # Organizar dados
    noise_levels = sorted(set(r['config']['noise_std'] for r in results))
    dropout_levels = sorted(set(r['config']['dropout_rate'] for r in results))

    # Criar matriz de degrada√ß√£o
    degradation_matrix = np.zeros((len(dropout_levels), len(noise_levels)))

    for result in results:
        noise_idx = noise_levels.index(result['config']['noise_std'])
        dropout_idx = dropout_levels.index(result['config']['dropout_rate'])
        degradation_matrix[dropout_idx, noise_idx] = result['degradation']

    # Plotar heatmap
    fig, ax = plt.subplots(figsize=(10, 8))
    im = ax.imshow(degradation_matrix, cmap='RdYlGn_r', aspect='auto')

    # Configurar eixos
    ax.set_xticks(np.arange(len(noise_levels)))
    ax.set_yticks(np.arange(len(dropout_levels)))
    ax.set_xticklabels([f'{n:.1f}' for n in noise_levels])
    ax.set_yticklabels([f'{d:.1f}' for d in dropout_levels])

    ax.set_xlabel('N√≠vel de Ru√≠do (œÉ)', fontsize=12)
    ax.set_ylabel('Taxa de Dropout', fontsize=12)
    ax.set_title('Degrada√ß√£o (%) vs. Ru√≠do e Dropout', fontsize=14, fontweight='bold')

    # Adicionar valores nas c√©lulas
    for i in range(len(dropout_levels)):
        for j in range(len(noise_levels)):
            text = ax.text(j, i, f'{degradation_matrix[i, j]:.1f}',
                          ha="center", va="center", color="black", fontsize=10)

    # Colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Degrada√ß√£o (%)', rotation=270, labelpad=20)

    plt.tight_layout()
    plt.savefig(dirs['plots'] / 'noise_dropout_heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()


def create_lr_sweep_plot(results, dirs):
    """Cria gr√°fico detalhado da varredura de learning rate."""

    lrs = [r['config']['learning_rate'] for r in results]
    clean_acc = [r['clean_accuracy'] for r in results]
    noisy_acc = [r['noisy_accuracy'] for r in results]
    degradation = [r['degradation'] for r in results]

    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    # Plot 1: Accuracy
    axes[0].semilogx(lrs, clean_acc, 'o-', label='Dados Limpos', linewidth=2)
    axes[0].semilogx(lrs, noisy_acc, 's-', label='Dados Ruidosos', linewidth=2)
    axes[0].set_xlabel('Learning Rate (log scale)', fontsize=12)
    axes[0].set_ylabel('Accuracy', fontsize=12)
    axes[0].set_title('Accuracy vs. Learning Rate', fontsize=14, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Plot 2: Degrada√ß√£o
    axes[1].semilogx(lrs, degradation, 'o-', color='red', linewidth=2)
    axes[1].set_xlabel('Learning Rate (log scale)', fontsize=12)
    axes[1].set_ylabel('Degrada√ß√£o (%)', fontsize=12)
    axes[1].set_title('Degrada√ß√£o vs. Learning Rate', fontsize=14, fontweight='bold')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(dirs['plots'] / 'lr_sweep.png', dpi=300, bbox_inches='tight')
    plt.close()


def create_activation_comparison_plot(results, dirs):
    """Cria gr√°fico comparativo de ativa√ß√µes."""

    names = [r['run_name'] for r in results]
    clean_acc = [r['clean_accuracy'] for r in results]
    noisy_acc = [r['noisy_accuracy'] for r in results]
    degradation = [r['degradation'] for r in results]

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    x = np.arange(len(names))
    width = 0.35

    # Accuracy comparison
    axes[0].bar(x - width/2, clean_acc, width, label='Dados Limpos', alpha=0.8)
    axes[0].bar(x + width/2, noisy_acc, width, label='Dados Ruidosos', alpha=0.8)
    axes[0].set_xlabel('Fun√ß√£o de Ativa√ß√£o', fontsize=12)
    axes[0].set_ylabel('Accuracy', fontsize=12)
    axes[0].set_title('Compara√ß√£o de Accuracy', fontsize=14, fontweight='bold')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(names, rotation=45, ha='right')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3, axis='y')

    # Degradation
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']
    axes[1].bar(names, degradation, alpha=0.8, color=colors)
    axes[1].set_xlabel('Fun√ß√£o de Ativa√ß√£o', fontsize=12)
    axes[1].set_ylabel('Degrada√ß√£o (%)', fontsize=12)
    axes[1].set_title('Degrada√ß√£o por Ru√≠do', fontsize=14, fontweight='bold')
    axes[1].tick_params(axis='x', rotation=45)
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig(dirs['plots'] / 'activation_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()


def main():
    """Menu principal para selecionar qual exemplo executar."""

    print("\n" + "="*80)
    print("EXEMPLOS DE SIMULA√á√ïES EM BATCH - MLP 64 NEUR√îNIOS")
    print("="*80 + "\n")

    print("Exemplos dispon√≠veis:")
    print("1. Comparar ru√≠do com e sem dropout (9 experimentos, ~10-15 min)")
    print("2. Varredura fina de learning rates (10 experimentos, ~15-20 min)")
    print("3. Compara√ß√£o de fun√ß√µes de ativa√ß√£o (4 experimentos, ~8-12 min)")
    print("4. Busca de configura√ß√£o √≥tima (27 experimentos, ~30-40 min)")
    print("5. Executar TODOS os exemplos (~60-90 min)")
    print("0. Sair")

    try:
        choice = input("\nEscolha uma op√ß√£o (0-5): ").strip()

        if choice == '1':
            example_1_compare_noise_with_dropout()
        elif choice == '2':
            example_2_learning_rate_sweep()
        elif choice == '3':
            example_3_activation_comparison()
        elif choice == '4':
            example_4_optimal_configuration_search()
        elif choice == '5':
            logger.info("\nExecutando TODOS os exemplos...")
            example_1_compare_noise_with_dropout()
            example_2_learning_rate_sweep()
            example_3_activation_comparison()
            example_4_optimal_configuration_search()
            logger.info("\nüéâ Todos os exemplos conclu√≠dos!")
        elif choice == '0':
            logger.info("Saindo...")
        else:
            logger.warning("Op√ß√£o inv√°lida!")

    except KeyboardInterrupt:
        logger.info("\n\nExecu√ß√£o interrompida pelo usu√°rio.")
    except Exception as e:
        logger.error(f"\nErro: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

