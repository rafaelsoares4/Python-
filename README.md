# ğŸ”¬ AnÃ¡lise de Robustez em Redes Neurais - MNIST

Este projeto demonstra o impacto de diferentes inicializaÃ§Ãµes de pesos na robustez de redes neurais quando expostas a ruÃ­do gaussiano, utilizando o dataset MNIST.

## ğŸ“‹ DescriÃ§Ã£o

O projeto compara quatro tipos de inicializaÃ§Ã£o de pesos:
- **GlorotUniform (Xavier)**: MantÃ©m variÃ¢ncia constante entre camadas
- **HeUniform**: Otimizada para ativaÃ§Ã£o ReLU
- **RandomNormal**: DistribuiÃ§Ã£o normal simples
- **Constant**: Valor fixo para comparaÃ§Ã£o

## ğŸš€ Funcionalidades

### Experimentos BÃ¡sicos
- âœ… Carregamento e prÃ©-processamento do dataset MNIST
- âœ… Treinamento de modelos MLP com diferentes inicializaÃ§Ãµes
- âœ… AdiÃ§Ã£o de ruÃ­do gaussiano para teste de robustez
- âœ… VisualizaÃ§Ã£o comparativa de resultados
- âœ… AnÃ¡lise de degradaÃ§Ã£o de performance por ruÃ­do

### ğŸ†• Experimentos AvanÃ§ados (Novo!)
- âœ… **VariaÃ§Ã£o de NÃ­veis de RuÃ­do**: Testa 8 nÃ­veis diferentes (0.05 a 0.4)
- âœ… **VariaÃ§Ã£o de Learning Rates**: 5 taxas diferentes (1e-4 a 1e-2)
- âœ… **VariaÃ§Ã£o de Batch Sizes**: 5 tamanhos (32 a 512)
- âœ… **Testes com Dropout**: 6 taxas de dropout (0.0 a 0.5)
- âœ… **FunÃ§Ãµes de AtivaÃ§Ã£o**: Compara ReLU, Tanh, ELU, Sigmoid
- âœ… **AnÃ¡lise SistemÃ¡tica**: 30+ experimentos automatizados
- âœ… **VisualizaÃ§Ãµes AvanÃ§adas**: GrÃ¡ficos multi-painel com anÃ¡lise detalhada

## ğŸ“Š Resultados

O notebook gera grÃ¡ficos comparativos mostrando:
- Accuracy em dados limpos vs. ruidosos
- DegradaÃ§Ã£o percentual de performance
- Tabela detalhada com mÃ©tricas

## ğŸ› ï¸ Tecnologias

- **Python 3.11**
- **TensorFlow 2.16.2**
- **NumPy**
- **Matplotlib**
- **Jupyter Notebook**

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ mnist_robustness_analysis.ipynb  # Notebook principal (experimentos bÃ¡sicos)
â”œâ”€â”€ main.py                          # Script de experimentos bÃ¡sicos
â”œâ”€â”€ advanced_experiments.py          # ğŸ†• Script de experimentos avanÃ§ados
â”œâ”€â”€ run_custom_experiments.py        # ğŸ†• Interface CLI para experimentos
â”œâ”€â”€ utils.py                         # FunÃ§Ãµes auxiliares
â”œâ”€â”€ requirements.txt                 # DependÃªncias
â”œâ”€â”€ README.md                        # Este arquivo
â”œâ”€â”€ EXPERIMENTS_GUIDE.md             # ğŸ†• Guia detalhado de experimentos
â””â”€â”€ .gitignore                       # Arquivos ignorados pelo Git
```

## ğŸ”§ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/rafaelsoares4/neural-network-robustness-analysis.git
cd neural-network-robustness-analysis
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

## ğŸƒâ€â™‚ï¸ Como Executar

### Experimentos BÃ¡sicos

1. **Via Jupyter Notebook:**
```bash
jupyter notebook mnist_robustness_analysis.ipynb
```

2. **Via Script Python:**
```bash
python main.py
```

### ğŸ†• Experimentos AvanÃ§ados

1. **Executar TODOS os experimentos avanÃ§ados:**
```bash
python advanced_experiments.py
```
*Tempo estimado: 30-45 minutos*

2. **Executar experimentos especÃ­ficos:**
```bash
# Apenas ruÃ­do e dropout
python run_custom_experiments.py --experiments noise dropout

# Apenas learning rate
python run_custom_experiments.py --experiments learning_rate

# Todos os experimentos
python run_custom_experiments.py --all
```

3. **Experimento customizado:**
```bash
python run_custom_experiments.py --custom \
  --initializer he \
  --optimizer adam \
  --learning-rate 0.001 \
  --dropout 0.3 \
  --noise 0.25 \
  --batch-size 128 \
  --epochs 20 \
  --name "meu_teste"
```

4. **Ver todas as opÃ§Ãµes:**
```bash
python run_custom_experiments.py --help
```

Para mais detalhes, consulte: **[EXPERIMENTS_GUIDE.md](EXPERIMENTS_GUIDE.md)**

## ğŸ“ˆ Resultados Esperados

- **HeUniform**: Geralmente melhor performance com ReLU
- **GlorotUniform**: Boa performance geral
- **RandomNormal**: Performance variÃ¡vel
- **Constant**: Baseline (geralmente pior performance)

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Adicionar novas funcionalidades
- Melhorar a documentaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Rafael Soares**
- GitHub: [@rafaelsoares4](https://github.com/rafaelsoares4)

## ğŸ“– DocumentaÃ§Ã£o Completa

Este projeto inclui documentaÃ§Ã£o extensa para diferentes nÃ­veis de usuÃ¡rio:

### ğŸš€ Para ComeÃ§ar Rapidamente
- **[QUICKSTART.md](QUICKSTART.md)** - Guia de inÃ­cio rÃ¡pido (5 minutos)
  - Teste de instalaÃ§Ã£o
  - Primeiros experimentos
  - Comandos essenciais

### ğŸ§ª Para Experimentar
- **[SIMULATION_SUGGESTIONS.md](SIMULATION_SUGGESTIONS.md)** - SugestÃµes especÃ­ficas de simulaÃ§Ãµes
  - 10 objetivos de pesquisa diferentes
  - SimulaÃ§Ãµes prontas para copiar/colar
  - AnÃ¡lise por cenÃ¡rio

### ğŸ“Š Para Entender em Profundidade
- **[EXPERIMENTS_GUIDE.md](EXPERIMENTS_GUIDE.md)** - Guia completo de experimentos
  - Detalhes de cada tipo de experimento
  - InterpretaÃ§Ã£o de resultados
  - ConfiguraÃ§Ãµes avanÃ§adas

### ğŸ¯ Fluxo Recomendado

```mermaid
Iniciante â†’ QUICKSTART.md â†’ Execute quick_test.py
    â†“
IntermediÃ¡rio â†’ SIMULATION_SUGGESTIONS.md â†’ Execute configuraÃ§Ãµes prÃ©-definidas
    â†“
AvanÃ§ado â†’ EXPERIMENTS_GUIDE.md â†’ Crie experimentos customizados
```

## ğŸ› ï¸ Scripts DisponÃ­veis

| Script | PropÃ³sito | Tempo | Dificuldade |
|--------|-----------|-------|-------------|
| `quick_test.py` | Validar instalaÃ§Ã£o | 2-3 min | â­ FÃ¡cil |
| `load_and_run_config.py` | Usar configs prÃ©-definidas | 5-10 min | â­ FÃ¡cil |
| `run_custom_experiments.py` | Experimentos customizados | 5-30 min | â­â­ MÃ©dio |
| `advanced_experiments.py` | Suite completa | 30-45 min | â­â­â­ AvanÃ§ado |

## ğŸ“š ReferÃªncias

- [TensorFlow Documentation](https://www.tensorflow.org/)
- [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a.html)
- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
