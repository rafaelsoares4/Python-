# ğŸ”¬ AnÃ¡lise de Robustez em Redes Neurais - MNIST

Este projeto demonstra o impacto de diferentes inicializaÃ§Ãµes de pesos na robustez de redes neurais quando expostas a ruÃ­do gaussiano, utilizando o dataset MNIST.

## ğŸ“‹ DescriÃ§Ã£o

O projeto compara quatro tipos de inicializaÃ§Ã£o de pesos:
- **GlorotUniform (Xavier)**: MantÃ©m variÃ¢ncia constante entre camadas
- **HeUniform**: Otimizada para ativaÃ§Ã£o ReLU
- **RandomNormal**: DistribuiÃ§Ã£o normal simples
- **Constant**: Valor fixo para comparaÃ§Ã£o

## ğŸš€ Funcionalidades

- âœ… Carregamento e prÃ©-processamento do dataset MNIST
- âœ… Treinamento de modelos MLP com diferentes inicializaÃ§Ãµes
- âœ… AdiÃ§Ã£o de ruÃ­do gaussiano para teste de robustez
- âœ… VisualizaÃ§Ã£o comparativa de resultados
- âœ… AnÃ¡lise de degradaÃ§Ã£o de performance por ruÃ­do

## ğŸ“Š Resultados

O notebook gera grÃ¡ficos comparativos mostrando:
- Accuracy em dados limpos vs. ruidosos
- DegradaÃ§Ã£o percentual de performance
- Tabela detalhada com mÃ©tricas

## ğŸ› ï¸ Tecnologias

- **Python 3.11**
- **TensorFlow 2.16.2**
- **NumPy**
- **Matplotlib**
- **Jupyter Notebook**

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ mnist_robustness_analysis.ipynb  # Notebook principal
â”œâ”€â”€ main.py                          # Script de experimentos
â”œâ”€â”€ utils.py                         # FunÃ§Ãµes auxiliares
â”œâ”€â”€ requirements.txt                 # DependÃªncias
â”œâ”€â”€ README.md                        # Este arquivo
â””â”€â”€ .gitignore                       # Arquivos ignorados pelo Git
```

## ğŸ”§ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/rafaelsoares4/neural-network-robustness-analysis.git
cd neural-network-robustness-analysis
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

## ğŸƒâ€â™‚ï¸ Como Executar

1. **Inicie o Jupyter Notebook:**
```bash
jupyter notebook mnist_robustness_analysis.ipynb
```

2. **Execute as cÃ©lulas em ordem** para ver a anÃ¡lise completa

## ğŸ“ˆ Resultados Esperados

- **HeUniform**: Geralmente melhor performance com ReLU
- **GlorotUniform**: Boa performance geral
- **RandomNormal**: Performance variÃ¡vel
- **Constant**: Baseline (geralmente pior performance)

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Adicionar novas funcionalidades
- Melhorar a documentaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Rafael Freitas**
- GitHub: [@rafaelsoares4](https://github.com/rafaelsoares4)

## ğŸ“š ReferÃªncias

- [TensorFlow Documentation](https://www.tensorflow.org/)
- [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a.html)
- [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
